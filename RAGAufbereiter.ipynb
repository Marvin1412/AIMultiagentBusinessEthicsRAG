{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP5w3gLssibKJB/7gU0NWD2"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["# ğŸ› ï¸ Installation (nur beim ersten Mal nÃ¶tig)\n","!apt-get install -y tesseract-ocr\n","!apt-get install -y tesseract-ocr-deu\n","!apt-get install -y poppler-utils\n","!pip install pytesseract pdf2image pymupdf transformers sentencepiece\n","\n","# ğŸ“¦ Imports\n","import os\n","import pytesseract\n","from pdf2image import convert_from_path\n","import fitz  # PyMuPDF\n","from transformers import MarianMTModel, MarianTokenizer\n","from google.colab import drive\n","\n","# ğŸ”§ Tesseract OCR Settings\n","pytesseract.pytesseract.tesseract_cmd = \"/usr/bin/tesseract\"\n","ocr_language = \"deu\"\n","\n","# ğŸ“‚ Drive mounten\n","drive.mount('/content/drive')\n","\n","# ğŸ”¹ Drive-Ordner (ggf. korrigieren)\n","drive_folder = \"/content/drive/MyDrive/data/\"\n","if not os.path.exists(drive_folder):\n","    drive_folder = \"/content/drive/My Drive/data/\"\n","\n"],"metadata":{"id":"Qq4y1QhxIpIB"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c8kqeECVapAe","executionInfo":{"status":"ok","timestamp":1749283609422,"user_tz":-120,"elapsed":181063,"user":{"displayName":"Patrick Hedfeld","userId":"02660593550160652346"}},"outputId":"81718921-1154-4e33-b5d9-25b86c23215f"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/transformers/models/marian/tokenization_marian.py:177: UserWarning: Recommended: pip install sacremoses.\n","  warnings.warn(\"Recommended: pip install sacremoses.\")\n"]},{"output_type":"stream","name":"stdout","text":["ğŸ” Versuche, Text direkt zu extrahieren...\n","âš ï¸ Kein Text gefunden â€“ OCR wird gestartet...\n","ğŸ–¼ï¸ OCR Seite 1\n","ğŸ–¼ï¸ OCR Seite 2\n","ğŸ–¼ï¸ OCR Seite 3\n","ğŸ–¼ï¸ OCR Seite 4\n","ğŸ–¼ï¸ OCR Seite 5\n","ğŸ–¼ï¸ OCR Seite 6\n","ğŸ–¼ï¸ OCR Seite 7\n","ğŸ–¼ï¸ OCR Seite 8\n","ğŸ–¼ï¸ OCR Seite 9\n","ğŸ–¼ï¸ OCR Seite 10\n","ğŸ–¼ï¸ OCR Seite 11\n","ğŸ–¼ï¸ OCR Seite 12\n","ğŸ–¼ï¸ OCR Seite 13\n","ğŸ–¼ï¸ OCR Seite 14\n","âœ… Ãœbersetzter Text gespeichert unter:\n","/content/drive/MyDrive/data/KarlHomann/MinnameierNormativitaetHomannEthik.txt\n"]}],"source":["# PDF-Datei\n","pdf_path = drive_folder + \"KarlHomann/MinnameierNormativitaetHomannEthik.pdf\"\n","\n","# Funktion: Direkttext aus PDF extrahieren\n","def extract_text_direct(pdf_path):\n","    doc = fitz.open(pdf_path)\n","    text = \"\".join([seite.get_text() for seite in doc])\n","    doc.close()\n","    return text.strip()\n","\n","# OCR-Fallback\n","def extract_text_ocr(pdf_path):\n","    images = convert_from_path(pdf_path)\n","    ocr_text = \"\"\n","    for i, img in enumerate(images):\n","        print(f\" OCR Seite {i+1}\")\n","        ocr_text += pytesseract.image_to_string(img, lang=ocr_language) + \"\\n\"\n","    return ocr_text.strip()\n","\n","#  Translator vorbereiten: Englisch â†’ Deutsch\n","model_name = \"Helsinki-NLP/opus-mt-en-de\"\n","tokenizer = MarianTokenizer.from_pretrained(model_name)\n","model = MarianMTModel.from_pretrained(model_name)\n","\n","def translate_text(text, max_chunk_len=512):\n","    sentences = text.split('. ')\n","    translated = []\n","    buffer = \"\"\n","    for sentence in sentences:\n","        if len(buffer + sentence) < max_chunk_len:\n","            buffer += sentence + \". \"\n","        else:\n","            tokens = tokenizer.prepare_seq2seq_batch([buffer], return_tensors=\"pt\")\n","            translated.append(model.generate(**tokens))\n","            buffer = sentence + \". \"\n","    if buffer:\n","        tokens = tokenizer.prepare_seq2seq_batch([buffer], return_tensors=\"pt\")\n","        translated.append(model.generate(**tokens))\n","\n","    output = []\n","    for t in translated:\n","        output.extend(tokenizer.batch_decode(t, skip_special_tokens=True))\n","    return \" \".join(output)\n","\n","#  Text extrahieren\n","print(\" Versuche, Text direkt zu extrahieren...\")\n","text = extract_text_direct(pdf_path)\n","if not text:\n","    print(\" Kein Text gefunden â€“ OCR wird gestartet...\")\n","    text = extract_text_ocr(pdf_path)\n","else:\n","    print(\" Text direkt gefunden.\")\n","\n","#  Bereinigen\n","clean_text = text.replace(\"\\n\", \" \").replace(\"  \", \" \").strip()\n","\n","#  Ãœbersetzen\n","#print(\" Ãœbersetze ins Deutsche...\")\n","#translated_text = translate_text(clean_text)\n","\n","#  Speichern\n","output_path = pdf_path.replace(\".pdf\", \".txt\") #\"_deutsch.txt\"\n","with open(output_path, \"w\", encoding=\"utf-8\") as f:\n","    f.write(translated_text)\n","\n","print(f\" Ãœbersetzter Text gespeichert unter:\\n{output_path}\")\n"]}]}